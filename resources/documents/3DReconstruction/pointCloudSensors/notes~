A useful search term is RGB-D sensors (D for depth)

The Microsoft Kinect was based of a primesense sensor.  Primesense then developed (recently) a extremely small version of the kinect (primesense capri) suitable for mobile devices.

Apple then bought Primesense and is currently systematically closing down any open development that relied on Primesense by not releasing the sensor outside of their devices and shutting down OpenNI.  

There is currently, however, a loophole.  Primesense apparently signed a contract with the developers of the Structure sensor before they were bought by Apple.  As it turns out, the Structure sensor is just a Primesense Capri with packaging and the Structure sensor people are providing an open SDK.  The only question is if Apple will find a way to cut off the supply of Primesense capri sensors.

The only other currently viable future option (meaning not just using a Kinect) is to use the Kinect 2 for Windows.  The problem with this is that it is a larger sensor and Microsoft is trying to make it so that it can only be used with a Windows SDK.  It would appear that there are efforts to get past that limitation (a open source library) but I am not yet sure how successful it is or how it get past it.

Harshad (roommate) said that the point cloud stitching originated with the "Kinect Fusion algorithm".  He also said that the PCL library was good for it.

Intel has recently released details about its "RealSense" technology.  It appears to be a sterio vision based point cloud sensor.  Luckily, Intel appears quite willing to sell the sensor directly (and will probably have decent linux support).  Since it is sterio vision based, the sensor will probably work well in direct sunlight but not as well in the dark.  The range is not known.

The sensor has not yet been released but they are allowing reservations to be placed for the developer kit ($100) and Charlie has placed a reservation (since the sensor is inexpensive and likely to be useful for several projects).


